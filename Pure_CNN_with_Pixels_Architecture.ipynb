{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMQxs5xmaogB",
        "outputId": "622b8637-86c3-4cfc-d76c-410b8ca70fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "HjHiUajezLpI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HguOc4I8UHzl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv3D, MaxPooling3D, Dropout, LSTM, Input, Concatenate, BatchNormalization\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input shapes\n",
        "CNN_in = Input(shape=(30, 200, 400, 3))\n",
        "\n",
        "CNN1 = Conv3D(filters=32, kernel_size=(5,5,5), activation='elu', padding='same',kernel_initializer='he_normal', name='conv2d_1')(CNN_in)\n",
        "B1 = BatchNormalization(name='batchnorm_1')(CNN1)\n",
        "MP1 = MaxPooling3D(pool_size=(2,2,2), name='maxpool2d_1')(B1)\n",
        "D1 = Dropout(0.2)(MP1)\n",
        "CNN2 = Conv3D(filters=64 ,kernel_size=(3,3,3),activation='elu',padding='same',kernel_initializer='he_normal', name='conv2d_2')(D1)\n",
        "B2 = BatchNormalization(name='batchnorm_2')(CNN2)\n",
        "MP2 = MaxPooling3D(pool_size=(2,2,2), name='maxpool2d_2')(B2)\n",
        "D2 = Dropout(0.4)(MP2)\n",
        "CNN3 = Conv3D(filters=128, kernel_size=(3,3,3),activation='elu',padding='same',kernel_initializer='he_normal', name='conv2d_3')(D2)\n",
        "B3 = BatchNormalization(name='batchnorm_3')(CNN3)\n",
        "MP3 = MaxPooling3D(pool_size=(2,2,2), name='maxpool2d_3')(B3)\n",
        "D3 = Dropout(0.2)(MP3)\n",
        "CNN4 = Conv3D(filters=128,kernel_size=(3,3,3),activation='elu',padding='same',kernel_initializer='he_normal', name='conv2d_4')(D3)\n",
        "B4 = BatchNormalization(name='batchnorm_4')(CNN4)\n",
        "MP4 = MaxPooling3D(pool_size=(2,2,2), name='maxpool2d_4')(B4)\n",
        "D4 = Dropout(0.4)(MP4)\n",
        "\n",
        "# Flatten\n",
        "F1 = Flatten()(D4)\n",
        "\n",
        "# Dense layers\n",
        "DS1 = Dense(32, activation='relu', kernel_initializer='he_normal')(F1)\n",
        "output = Dense(10, activation='softmax')(DS1)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs = CNN_in, outputs=output)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DrM31Tjjn6Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSwSOu9webBR",
        "outputId": "720ce636-77b8-4445-c822-5670c48ef94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 30, 200, 400, 3   0         \n",
            "                             )]                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv3D)           (None, 30, 200, 400, 32   12032     \n",
            "                             )                                   \n",
            "                                                                 \n",
            " batchnorm_1 (BatchNormaliz  (None, 30, 200, 400, 32   128       \n",
            " ation)                      )                                   \n",
            "                                                                 \n",
            " maxpool2d_1 (MaxPooling3D)  (None, 15, 100, 200, 32   0         \n",
            "                             )                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 100, 200, 32   0         \n",
            "                             )                                   \n",
            "                                                                 \n",
            " conv2d_2 (Conv3D)           (None, 15, 100, 200, 64   55360     \n",
            "                             )                                   \n",
            "                                                                 \n",
            " batchnorm_2 (BatchNormaliz  (None, 15, 100, 200, 64   256       \n",
            " ation)                      )                                   \n",
            "                                                                 \n",
            " maxpool2d_2 (MaxPooling3D)  (None, 7, 50, 100, 64)    0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 50, 100, 64)    0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv3D)           (None, 7, 50, 100, 128)   221312    \n",
            "                                                                 \n",
            " batchnorm_3 (BatchNormaliz  (None, 7, 50, 100, 128)   512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " maxpool2d_3 (MaxPooling3D)  (None, 3, 25, 50, 128)    0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3, 25, 50, 128)    0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv3D)           (None, 3, 25, 50, 128)    442496    \n",
            "                                                                 \n",
            " batchnorm_4 (BatchNormaliz  (None, 3, 25, 50, 128)    512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " maxpool2d_4 (MaxPooling3D)  (None, 1, 12, 25, 128)    0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1, 12, 25, 128)    0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 38400)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                1228832   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1961770 (7.48 MB)\n",
            "Trainable params: 1961066 (7.48 MB)\n",
            "Non-trainable params: 704 (2.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Npz"
      ],
      "metadata": {
        "id": "kSIVp2chzs2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the keypoints data from the npz file\n",
        "data1 = np.load('/content/drive/MyDrive/lsa64/Pixel_Npzs/pixels_data_i3_j4_k3.npz')\n",
        "\n",
        "labels = data1['labels']\n",
        "pixels = data1['pixels']\n",
        "\n",
        "\n",
        "print(\"Label:\")\n",
        "print(type(labels.item()))\n",
        "\n",
        "print(\"pixels:\")\n",
        "print(pixels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQg_0S0DfK48",
        "outputId": "a6abad6d-a876-4101-aef0-eb56c56cc86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:\n",
            "<class 'str'>\n",
            "pixels:\n",
            "(23, 200, 400, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding Pixels"
      ],
      "metadata": {
        "id": "Rn7fgqajzvfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_or_truncate_pixels(pixels, target_frames=30):\n",
        "    current_frames, frame_height, frame_width, _ = pixels.shape\n",
        "\n",
        "    if current_frames < target_frames:\n",
        "        # If there are fewer frames, pad the pixels with the last frame\n",
        "        padding = target_frames - current_frames\n",
        "        pad_frame = pixels[-1:]  # Use the last frame for padding\n",
        "        pixels = np.concatenate([pixels] + [pad_frame] * padding)\n",
        "    elif current_frames > target_frames:\n",
        "        # If there are more frames, truncate from the back\n",
        "        pixels = pixels[-target_frames:]\n",
        "\n",
        "    return pixels"
      ],
      "metadata": {
        "id": "1k6td65Te846"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early Stopping"
      ],
      "metadata": {
        "id": "op-YNFaklc6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy',min_delta=0.00005,patience=7,verbose=1,\n",
        "    restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy',factor=0.5,patience=4,min_lr=1e-7,verbose=1)\n",
        "\n",
        "callbacks = [early_stopping,lr_scheduler]"
      ],
      "metadata": {
        "id": "xKQShVZ8d1pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pixels_folder = '/content/drive/MyDrive/lsa64/Pixel_Npzs'\n",
        "batch_size = 3"
      ],
      "metadata": {
        "id": "grrzLv_YJ-6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pixel_data(label, person, selected_videos):\n",
        "    pixel_data = []\n",
        "    labels_data = []\n",
        "    for k in selected_videos:\n",
        "        filename = f'pixels_data_i{label}_j{person}_k{k}.npz'\n",
        "        file_path = os.path.join(pixels_folder, filename)\n",
        "        data = np.load(file_path)\n",
        "        label = int(data['labels'])\n",
        "        labels_data.append(label)\n",
        "        pixel_data.append(pad_or_truncate_pixels(data['pixels']))  # Adjust this based on your data structure\n",
        "    return np.stack(pixel_data, axis=0), labels_data"
      ],
      "metadata": {
        "id": "O3CQYVleML9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "def train_batch_generator():\n",
        "    num_labels = 10\n",
        "    num_persons = 10\n",
        "    selected_videos = [1, 2, 3]  # Specify the selected videos (k values)\n",
        "    batch_size = 3\n",
        "\n",
        "    while True:\n",
        "        for label in range(1, num_labels+1):\n",
        "            for person in range(1, num_persons + 1):\n",
        "                # keypoints_batch = load_keypoints_data(label, person, selected_videos)\n",
        "                pixel_batch, labels_batch = load_pixel_data(label, person, selected_videos)\n",
        "                num_videos = len(selected_videos)\n",
        "                num_batches = num_videos // batch_size\n",
        "\n",
        "                for batch_num in range(num_batches):\n",
        "                    start = batch_num * batch_size\n",
        "                    end = (batch_num + 1) * batch_size\n",
        "                    labels_array = np.array(labels_batch) - 1\n",
        "                    one_hot_labels = to_categorical(labels_array, num_labels)\n",
        "                    yield (\n",
        "                        pixel_batch[start:end]\n",
        "                        # keypoints_batch[start:end]\n",
        "                    ), one_hot_labels[start:end]\n",
        "                    del pixel_batch, one_hot_labels\n"
      ],
      "metadata": {
        "id": "VIGEHS3GzUxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_batch_generator():\n",
        "    num_labels = 10\n",
        "    num_persons = 10\n",
        "    selected_videos = [4]  # Specify the selected videos (k values)\n",
        "    batch_size = 1\n",
        "\n",
        "    while True:\n",
        "        for label in range(1, num_labels+1):\n",
        "            for person in range(1, num_persons + 1):\n",
        "                # keypoints_batch = load_keypoints_data(label, person, selected_videos)\n",
        "                pixel_batch, labels_batch = load_pixel_data(label, person, selected_videos)\n",
        "                num_videos = len(selected_videos)\n",
        "                num_batches = num_videos // batch_size\n",
        "\n",
        "                for batch_num in range(num_batches):\n",
        "                    start = batch_num * batch_size\n",
        "                    end = (batch_num + 1) * batch_size\n",
        "                    labels_array = np.array(labels_batch) - 1\n",
        "                    one_hot_labels = to_categorical(labels_array, num_labels)\n",
        "                    yield (\n",
        "                        pixel_batch[start:end]\n",
        "                        # keypoints_batch[start:end]\n",
        "                    ), one_hot_labels[start:end]\n",
        "                    del pixel_batch, one_hot_labels"
      ],
      "metadata": {
        "id": "OCOKsYRBpoGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "train_generator = train_batch_generator()\n",
        "val_generator = val_batch_generator()\n",
        "\n",
        "history = model.fit(train_generator, batch_size = 3,steps_per_epoch = 101, epochs = 20, validation_data = val_generator\n",
        "                    ,validation_steps = 101, validation_batch_size=1, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPeRhIy5-iEn",
        "outputId": "318fff49-594a-4a77-96ac-20a4ef76c62b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "101/101 [==============================] - 391s 4s/step - loss: 25.8177 - accuracy: 0.4356 - val_loss: 8.5368 - val_accuracy: 0.0198 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "101/101 [==============================] - 54s 539ms/step - loss: 2.4363 - accuracy: 0.0000e+00 - val_loss: 2.5995 - val_accuracy: 0.1287 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "101/101 [==============================] - 55s 548ms/step - loss: 2.4566 - accuracy: 0.0132 - val_loss: 2.1264 - val_accuracy: 0.1782 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "101/101 [==============================] - 52s 517ms/step - loss: 2.3282 - accuracy: 0.0825 - val_loss: 2.2765 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "101/101 [==============================] - 56s 556ms/step - loss: 2.2885 - accuracy: 0.0099 - val_loss: 2.2589 - val_accuracy: 0.1782 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "101/101 [==============================] - 53s 525ms/step - loss: 2.2885 - accuracy: 0.0099 - val_loss: 2.2521 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "101/101 [==============================] - ETA: 0s - loss: 2.2884 - accuracy: 0.0099\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "101/101 [==============================] - 57s 561ms/step - loss: 2.2884 - accuracy: 0.0099 - val_loss: 2.2511 - val_accuracy: 0.1683 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "101/101 [==============================] - 53s 527ms/step - loss: 2.2841 - accuracy: 0.0792 - val_loss: 2.2490 - val_accuracy: 0.1683 - lr: 5.0000e-04\n",
            "Epoch 9/20\n",
            "101/101 [==============================] - 57s 561ms/step - loss: 2.2841 - accuracy: 0.0792 - val_loss: 2.2479 - val_accuracy: 0.1683 - lr: 5.0000e-04\n",
            "Epoch 10/20\n",
            "101/101 [==============================] - ETA: 0s - loss: 2.2840 - accuracy: 0.0693Restoring model weights from the end of the best epoch: 3.\n",
            "101/101 [==============================] - 53s 529ms/step - loss: 2.2840 - accuracy: 0.0693 - val_loss: 2.2462 - val_accuracy: 0.1683 - lr: 5.0000e-04\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_batch_generator():\n",
        "    num_labels = 10\n",
        "    num_persons = 10\n",
        "    selected_videos = [5]  # Specify the selected videos (k values)\n",
        "    batch_size = 1\n",
        "\n",
        "    while True:\n",
        "        for label in range(1, num_labels + 1):\n",
        "            for person in range(1, num_persons + 1):\n",
        "                # keypoints_batch = load_keypoints_data(label, person, selected_videos)\n",
        "                pixel_batch, labels_batch = load_pixel_data(label, person, selected_videos)\n",
        "                num_videos = len(selected_videos)\n",
        "                num_batches = num_videos // batch_size\n",
        "\n",
        "                for batch_num in range(num_batches):\n",
        "                    start = batch_num * batch_size\n",
        "                    end = (batch_num + 1) * batch_size\n",
        "                    labels_array = np.array(labels_batch) - 1\n",
        "                    one_hot_labels = to_categorical(labels_array, num_labels)\n",
        "                    yield (\n",
        "                        pixel_batch[start:end]\n",
        "                        # keypoints_batch[start:end]\n",
        "                    ), one_hot_labels[start:end]\n",
        "                    del pixel_batch, one_hot_labels\n",
        "\n"
      ],
      "metadata": {
        "id": "lOX7mcPjqY3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_batch_generator()\n",
        "test_results = model.evaluate(test_generator, steps=101)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptwY57cGwCJ1",
        "outputId": "c15d3eeb-64de-4392-8c75-cdd159a94ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101/101 [==============================] - 92s 917ms/step - loss: 2.1194 - accuracy: 0.1881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf2SqiLBwPPs",
        "outputId": "14acfeaa-fd30-4151-85ce-2ac82c5aaa82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0733212232589722, 0.6393442749977112]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}