{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMQxs5xmaogB",
        "outputId": "6d5f87b4-5724-411a-ef56-a9ff32a49fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "sb8_Ndry4Tpx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HguOc4I8UHzl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv3D, MaxPooling3D, Dropout, LSTM, Input, Concatenate, BatchNormalization\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input shapes\n",
        "RNN_in = Input(shape=(30, 123))\n",
        "\n",
        "# LSTM\n",
        "RNN1 = LSTM(units=128, return_sequences=True)(RNN_in)\n",
        "RNN2 = LSTM(units=64, return_sequences=True, dropout = 0.3)(RNN1)\n",
        "\n",
        "# Flatten\n",
        "F2 = Flatten()(RNN2)\n",
        "\n",
        "# Dense layers\n",
        "DS1 = Dense(64, activation='relu', kernel_initializer='he_normal')(F2)\n",
        "output = Dense(10, activation='softmax')(DS1)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs= RNN_in, outputs=output)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DrM31Tjjn6Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSwSOu9webBR",
        "outputId": "f694796e-7e8d-4b6b-871e-80bcc7389abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 30, 123)]         0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 30, 128)           129024    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 30, 64)            49408     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1920)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                122944    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 302026 (1.15 MB)\n",
            "Trainable params: 302026 (1.15 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Npz"
      ],
      "metadata": {
        "id": "Gq5BWdO54eaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the keypoints data from the npz file\n",
        "data1 = np.load('/content/drive/MyDrive/lsa64/Npzs/keypoints_data_i2_j4_k3.npz')\n",
        "\n",
        "labels = data1['labels']\n",
        "keypoints = data1['keypoints']\n",
        "\n",
        "\n",
        "print(\"Label:\")\n",
        "print(type(labels.item()))\n",
        "\n",
        "print(\"Keypoints:\")\n",
        "print(keypoints.shape)"
      ],
      "metadata": {
        "id": "SSg2lpm32pbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding Key points"
      ],
      "metadata": {
        "id": "Zs468SVj4jJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def pad_or_truncate_keypoints(keypoints, target_frames=30):\n",
        "    current_frames = len(keypoints)\n",
        "\n",
        "    if current_frames < target_frames:\n",
        "      # If there are fewer frames, pad the keypoints with the last frame\n",
        "      padding = target_frames - current_frames\n",
        "      pad_value = np.expand_dims(keypoints[-1], axis=0)  # Take the last frame to pad\n",
        "      pad_values = np.tile(pad_value, (padding, 1, 1))\n",
        "      keypoints = np.concatenate((keypoints, pad_values), axis=0)\n",
        "    elif current_frames > target_frames:\n",
        "        excess_frames = current_frames - target_frames\n",
        "        front_truncate = excess_frames // 2\n",
        "        back_truncate = excess_frames - front_truncate\n",
        "        keypoints = keypoints[front_truncate:-back_truncate]\n",
        "    return keypoints"
      ],
      "metadata": {
        "id": "zlw1kudAcaNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early Stopping"
      ],
      "metadata": {
        "id": "op-YNFaklc6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy',min_delta=0.00005,patience=7,verbose=1,\n",
        "    restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy',factor=0.5,patience=4,min_lr=1e-7,verbose=1)\n",
        "\n",
        "callbacks = [early_stopping,lr_scheduler]"
      ],
      "metadata": {
        "id": "xKQShVZ8d1pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keypoints_folder = '/content/drive/MyDrive/lsa64/Npzs'\n",
        "batch_size = 3"
      ],
      "metadata": {
        "id": "grrzLv_YJ-6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_keypoints_data(label, person, selected_videos):\n",
        "    keypoints_data = []\n",
        "    labels_data = []\n",
        "    for k in selected_videos:\n",
        "        filename = f'keypoints_data_i{label}_j{person}_k{k}.npz'\n",
        "        file_path = os.path.join(keypoints_folder, filename)\n",
        "        data = np.load(file_path)\n",
        "        label = int(data['labels'])\n",
        "        labels_data.append(label)\n",
        "        keypoints_data.append(pad_or_truncate_keypoints(data['keypoints']).reshape(30,123))\n",
        "    return np.stack(keypoints_data,  axis=0), labels_data"
      ],
      "metadata": {
        "id": "PZKrHqN1J_Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "def train_batch_generator():\n",
        "    num_labels = 10\n",
        "    num_persons = 10\n",
        "    selected_videos = [1, 2, 3]  # Specify the selected videos (k values)\n",
        "    batch_size = 3\n",
        "\n",
        "    while True:\n",
        "        for label in range(1, num_labels+1):\n",
        "            for person in range(1, num_persons + 1):\n",
        "                keypoints_batch, labels_batch = load_keypoints_data(label, person, selected_videos)\n",
        "                #pixel_batch, labels_batch = load_pixel_data(label, person, selected_videos)\n",
        "                num_videos = len(selected_videos)\n",
        "                num_batches = num_videos // batch_size\n",
        "\n",
        "                for batch_num in range(num_batches):\n",
        "                    start = batch_num * batch_size\n",
        "                    end = (batch_num + 1) * batch_size\n",
        "                    labels_array = np.array(labels_batch) - 1\n",
        "                    one_hot_labels = to_categorical(labels_array, num_labels)\n",
        "                    yield (\n",
        "                        #pixel_batch[start:end],\n",
        "                        keypoints_batch[start:end]\n",
        "                    ), one_hot_labels[start:end]\n",
        "                    del keypoints_batch, one_hot_labels\n"
      ],
      "metadata": {
        "id": "VIGEHS3GzUxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_batch_generator():\n",
        "    num_labels = 10\n",
        "    num_persons = 10\n",
        "    selected_videos = [4]  # Specify the selected videos (k values)\n",
        "    batch_size = 1\n",
        "\n",
        "    while True:\n",
        "        for label in range(1, num_labels+1):\n",
        "            for person in range(1, num_persons + 1):\n",
        "                keypoints_batch,labels_batch = load_keypoints_data(label, person, selected_videos)\n",
        "                #pixel_batch, labels_batch = load_pixel_data(label, person, selected_videos)\n",
        "                num_videos = len(selected_videos)\n",
        "                num_batches = num_videos // batch_size\n",
        "\n",
        "                for batch_num in range(num_batches):\n",
        "                    start = batch_num * batch_size\n",
        "                    end = (batch_num + 1) * batch_size\n",
        "                    labels_array = np.array(labels_batch) - 1\n",
        "                    one_hot_labels = to_categorical(labels_array, num_labels)\n",
        "                    yield (\n",
        "                        #pixel_batch[start:end],\n",
        "                        keypoints_batch[start:end]\n",
        "                    ), one_hot_labels[start:end]\n",
        "                    del keypoints_batch, one_hot_labels"
      ],
      "metadata": {
        "id": "OCOKsYRBpoGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "train_generator = train_batch_generator()\n",
        "val_generator = val_batch_generator()\n",
        "\n",
        "history = model.fit(train_generator, batch_size = 3,steps_per_epoch = 11, epochs = 20, validation_data = val_generator\n",
        "                    ,validation_steps = 11, validation_batch_size=1, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPeRhIy5-iEn",
        "outputId": "2ab5149e-952b-4ae9-b7bf-9f9770b446dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "11/11 [==============================] - 0s 40ms/step - loss: 0.8218 - accuracy: 0.7273 - val_loss: 0.5439 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 2/20\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 3.6177 - accuracy: 0.2424 - val_loss: 3.3952 - val_accuracy: 0.5455 - lr: 5.0000e-04\n",
            "Epoch 3/20\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 2.9005 - accuracy: 0.2727 - val_loss: 0.7408 - val_accuracy: 0.6364 - lr: 5.0000e-04\n",
            "Epoch 4/20\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.7947 - accuracy: 0.8182 - val_loss: 0.8048 - val_accuracy: 0.7273 - lr: 5.0000e-04\n",
            "Epoch 5/20\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 1.0186 - accuracy: 0.6667\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.9601 - accuracy: 0.6667 - val_loss: 2.7287 - val_accuracy: 0.3636 - lr: 5.0000e-04\n",
            "Epoch 6/20\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.4462 - accuracy: 0.7273 - val_loss: 4.1470 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
            "Epoch 7/20\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.1649 - accuracy: 0.3333 - val_loss: 5.0357 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
            "Epoch 8/20\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 2.0267 - accuracy: 0.0333Restoring model weights from the end of the best epoch: 1.\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 1.9416 - accuracy: 0.0303 - val_loss: 6.3681 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
            "Epoch 8: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_batch_generator():\n",
        "    num_labels = 10\n",
        "    num_persons = 10\n",
        "    selected_videos = [5]  # Specify the selected videos (k values)\n",
        "    batch_size = 1\n",
        "\n",
        "    while True:\n",
        "        for label in range(1, num_labels + 1):\n",
        "            for person in range(1, num_persons + 1):\n",
        "                keypoints_batch,labels_batch = load_keypoints_data(label, person, selected_videos)\n",
        "                #pixel_batch, labels_batch = load_pixel_data(label, person, selected_videos)\n",
        "                num_videos = len(selected_videos)\n",
        "                num_batches = num_videos // batch_size\n",
        "\n",
        "                for batch_num in range(num_batches):\n",
        "                    start = batch_num * batch_size\n",
        "                    end = (batch_num + 1) * batch_size\n",
        "                    labels_array = np.array(labels_batch) - 1\n",
        "                    one_hot_labels = to_categorical(labels_array, num_labels)\n",
        "                    yield (\n",
        "                        #pixel_batch[start:end],\n",
        "                        keypoints_batch[start:end]\n",
        "                    ), one_hot_labels[start:end]\n",
        "                    del keypoints_batch, one_hot_labels\n",
        "\n"
      ],
      "metadata": {
        "id": "lOX7mcPjqY3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_batch_generator()\n",
        "test_results = model.evaluate(test_generator, steps=11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptwY57cGwCJ1",
        "outputId": "e47d44ac-eef2-4af6-83f5-f8b632d0f9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 0s 16ms/step - loss: 0.5501 - accuracy: 0.9091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf2SqiLBwPPs",
        "outputId": "502721f7-bb53-48e9-b773-ac63209f207c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5501289963722229, 0.9090909361839294]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}